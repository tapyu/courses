{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import unique, sum, array, zeros, inf\n",
    "from numpy.linalg import inv, det\n",
    "from numpy.random import permutation\n",
    "from statistics import mean, median, stdev\n",
    "from math import log as ln\n",
    "import itertools\n",
    "\n",
    "df = pd.read_csv('./dataset/parkinsons.csv')\n",
    "\n",
    "# output vector\n",
    "y = df['status'].values\n",
    "# dictionary with all estimators\n",
    "estimators = {i:{'y_hat': [], 'accuracies': [], 'best accuracy': 0, 'worst accuracy': inf} for i in ('gaussian bayesian classifier eq.14', 'gaussian bayesian classifier eq.44', 'ML with pool matrix eq.17', 'ML with pool matrix eq.39')}\n",
    "# instances matrix -> [p attributes x N instances]\n",
    "X = df.drop(['status', 'name'], axis=1).values.T\n",
    "\n",
    "# number of classes 0 -> healthy; 1 -> Parkinson's disease (PD)\n",
    "K = unique(y).size\n",
    "# N -> number of instances; p -> number of attributes, OBS: x_n \\in \\Real^p, for 1<=n<=N\n",
    "p, N = X.shape\n",
    "# number of iterations\n",
    "N_iter = 100\n",
    "# number of instances of the train set\n",
    "N_trn = N*80//100 # 80% of the instances for train and 20% for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix of a vector of random variables\n",
    "$$\\mathbf{x} = \\begin{bmatrix} x_1, x_2, \\cdots, x_p \\end{bmatrix}^\\mathsf{T} \\in \\mathbb{R}^p$$\n",
    "is defined as the second-order central moments of its components, that is\n",
    "\n",
    "$\\mathbf{C}_k = \\begin{bmatrix}\n",
    "E[(x_1 - m_1)^2]  & E[(x_1 - m_1)(x_2 - m_2)] & \\cdots & E[(x_1 - m_1)(x_p - m_p)] \\\\\n",
    "E[(x_2 - m_2)(x_1 - m_1)] & E[(x_2 - m_2)^2]  & \\cdots & E[(x_2 - m_2)(x_p - m_p)] \\\\\n",
    "\\vdots    & \\vdots    & \\ddots & \\vdots \\\\\n",
    "E[(x_p - m_p)(x_1 - m_1)] & E[(x_p - m_p)(x_2 - m_2)] & \\cdots & E[(x_p - m_p)^2]\n",
    "\\end{bmatrix},$\n",
    "\n",
    "where $E[x_i]\\triangleq m_k$ denotes the expected value of the random variable $x_i$ and $k\\in \\left\\{1, 2, \\cdots, K\\right\\}$ is the $k$-th class, $\\omega_k$, in which the covariance matrix is estimated, being $K$ the total number of classes. As it is the estimation of the $k$-th class, obviously, $\\mathbf{x}$ belongs to this class.\n",
    "\n",
    "Note that the main diagonal of $\\mathbf{C}_k$ is the variance of $x_i$, hereafter denoted as $\\sigma_k^2$. The elements outside of the main diagonal are the covariance, which can be written as\n",
    "$$E[(x_i - m_i)(x_l - m_l)] \\triangleq \\sigma_{il} = \\sigma_{i}\\sigma_{l}\\rho_{il}$$\n",
    "\n",
    "where the last equation comes from the correlation coefficient ($\\rho_{il}$) definition.\n",
    "\n",
    "Hence, the covariance matrix can be rewritten as\n",
    "\n",
    "$\\mathbf{C}_k = \\begin{bmatrix}\n",
    "\\sigma_1^2  & \\sigma_{1}\\sigma_{2}\\rho_{12} & \\cdots & \\sigma_{1}\\sigma_{p}\\rho_{1p} \\\\\n",
    "\\sigma_{2}\\sigma_{1}\\rho_{21} & \\sigma_2^2  & \\cdots & \\sigma_{2}\\sigma_{p}\\rho_{2p} \\\\\n",
    "\\cdot    & \\cdot    & \\ddots & \\vdots \\\\\n",
    "\\sigma_{p}\\sigma_{1}\\rho_{p1} & \\sigma_{p}\\sigma_{2}\\rho_{p2} & \\cdots & \\sigma_p^2\n",
    "\\end{bmatrix},$\n",
    "\n",
    "Using the matrix notation, $\\mathbf{C}_k$ can be written as\n",
    "\\begin{align}\n",
    "\\mathbf{C}_k & = E\\left[(\\mathbf{x} - \\mathbf{m}_k)(\\mathbf{x} - \\mathbf{m}_k)^\\mathsf{T}\\right] \\\\\n",
    "& = E\\left[\\mathbf{x}\\mathbf{x}^\\mathsf{T} - \\mathbf{x}\\mathbf{m}_k^\\mathsf{T} - \\mathbf{m}_k\\mathbf{x}^\\mathsf{T} + \\mathbf{m}_k\\mathbf{m}_k^\\mathsf{T}\\right] \\\\\n",
    "& = E\\left[\\mathbf{x}\\mathbf{x}^\\mathsf{T}\\right] - E\\left[\\mathbf{x}\\right]\\mathbf{m}_k^\\mathsf{T} - \\mathbf{m}_k E\\left[\\mathbf{x}\\right]^\\mathsf{T} + \\mathbf{m}_k\\mathbf{m}_k^\\mathsf{T} \\\\\n",
    "& = \\mathbf{R}_k - \\mathbf{m}_k\\mathbf{m}_k^\\mathsf{T},\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "$\\mathbf{R}_k = \\begin{bmatrix}\n",
    "E[x_1^2]  & E[x_1x_2] & \\cdots & E[x_1x_p] \\\\\n",
    "E[x_2x_1] & E[x_2^2]  & \\cdots & E[x_2x_p] \\\\\n",
    "\\vdots    & \\vdots    & \\ddots & \\vdots \\\\\n",
    "E[x_px_1] & E[x_px_2] & \\cdots & E[x_p^2]\n",
    "\\end{bmatrix} = E[\\mathbf{x}\\mathbf{x}^\\mathsf{T}],$\n",
    "and\n",
    "$\\mathbf{m}_k = \\begin{bmatrix}\n",
    "m_1  & m_2 & \\cdots & m_p\n",
    "\\end{bmatrix},$\n",
    "are the correlation matrix and the mean vector of $\\mathbf{x}$, respectively.\n",
    "\n",
    "Using a set of $N_k$ realizations $\\left\\{\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\cdots, \\mathbf{x}_{N_k}\\right\\}$, where all vectors belong to $\\omega_k$, the estimator of $\\mathbf{R}_k$ can be calculated as\n",
    "\\begin{align}\n",
    "\\mathbf{\\hat{R}}_k = \\frac{1}{N_k} \\sum_{n=1}^{N_k} \\mathbf{x}_{n}\\mathbf{x}_n\n",
    "\\end{align}\n",
    "\n",
    "The estimation of the autocorrelation matrix can be computed faster using a matrix notation of all realization of the vector $\\mathbf{x}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{X}_k = \\left\\{\\mathbf{x}_{1}\\mid \\mathbf{x}_{2}\\mid \\cdots\\mid \\mathbf{x}_{N_k} \\right\\}\n",
    "\\end{align}\n",
    "The estimation of the correlation matrix is simply given by\n",
    "\\begin{align}\n",
    "\\mathbf{\\hat{R}}_k = \\frac{1}{N_k}\\mathbf{X}_k\\mathbf{X}_k^\\mathsf{T}\n",
    "\\end{align}\n",
    "\n",
    "and the estimation of the mean vector is given by\n",
    "$$\\mathbf{\\hat{m}}_k = \\frac{1}{N_k} \\sum_{n=1}^{N_k} \\mathbf{x}_{n}$$\n",
    "\n",
    "Of any input vector\n",
    "\n",
    "For a given input vector $\\mathbf{x}_{n}$ that can belong to any class, one can compute the square of the Mahalanobis distance between that new instance for the $k$-th class, $\\omega_k$.\n",
    "\n",
    "\\begin{align}\n",
    "    Q_k \\left( \\mathbf{x}_{n} \\right) = \\left(\\mathbf{x}_{n} - \\hat{\\mathbf{m}}_k\\right)^\\mathsf{T} \\hat{\\mathbf{C}}_k^{-1} \\left(\\mathbf{x}_{n} - \\hat{\\mathbf{m}}_k\\right)\n",
    "\\end{align} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize instances\n",
    "permut = permutation(N)\n",
    "X, y = X[:,permut], y[permut]\n",
    "\n",
    "trn_tst_iterator = itertools.permutations(range(N))\n",
    "for i, trn_tst in enumerate(trn_tst_iterator):\n",
    "    # generate train and test dataset\n",
    "    X_trn, y_trn = X[:, trn_tst[:N_trn]], y[array(trn_tst[:N_trn])]\n",
    "    X_tst, y_tst = X[:, trn_tst[N_trn:]], y[array(trn_tst[N_trn:])]\n",
    "\n",
    "    ### training phase\n",
    "    # p_k -> relative frequency (estimator) of P(wk)\n",
    "    p_0, p_1 = (y_trn[y_trn==k].size / N_trn for k in range(K))\n",
    "    # X_k -> instances that belongs to class wk\n",
    "    X_0, X_1 = (X_trn[:,y_trn==k] for k in range(K))\n",
    "    # N_k -> number of instances that belong to class wk\n",
    "    N_0, N_1 = X_0.shape[1], X_1.shape[1]\n",
    "    # m_k -> mean vector of the class wk\n",
    "    m_0, m_1 = sum(X_0, axis=1, keepdims=True)/N_0, sum(X_1, axis=1, keepdims=True)/N_1\n",
    "    # R_k -> correlation matrix of the class wk\n",
    "    R_0 = X_0 @ X_0.T / N_0\n",
    "    R_1 = X_1 @ X_1.T / N_1\n",
    "    # C_k -> covariance matrix of the class wk\n",
    "    C_0 = R_0 - m_0@m_0.T\n",
    "    C_1 = R_1 - m_1@m_1.T\n",
    "\n",
    "    ### test phase\n",
    "    # appending a new counter to the next test phase\n",
    "    for estimator in estimators.keys():\n",
    "        estimators[estimator]['accuracies'].append(0)\n",
    "    for x, y_n in zip(X_tst.T, y_tst): # for each instance (each column)\n",
    "        x = x[:,None] # make it a px1 vector\n",
    "        confusion_matrices = {i: zeros((K, K)) for i in estimators.keys()}\n",
    "\n",
    "        ### gaussian bayesian classifier -> eq.14\n",
    "        # Q_k Mahalanobis distance of x from the class w_k\n",
    "        Q_0 = (x - m_0).T @ inv(C_0) @ (x - m_0)\n",
    "        Q_1 = (x - m_1).T @ inv(C_1) @ (x - m_1)\n",
    "        \n",
    "        g_0 = -.5*Q_0 - .5*ln(det(C_0)) + ln(p_0)\n",
    "        g_1 = -.5*Q_1 - .5*ln(det(C_1)) + ln(p_1)\n",
    "        # decision criteria eq.7\n",
    "        estimators['gaussian bayesian classifier eq.14']['y_hat'].append(0) if g_0 > g_1 else estimators['gaussian bayesian classifier eq.14']['y_hat'].append(1)\n",
    "\n",
    "        ### gaussian bayesian classifier -> eq.44\n",
    "        g_0 = -.5*x.T@inv(C_0)@x + m_0.T@inv(C_0)@x - .5*m_0.T@inv(C_0)@m_0 - .5*ln(det(C_0))\n",
    "        g_1 = -.5*x.T@inv(C_1)@x + m_1.T@inv(C_1)@x - .5*m_1.T@inv(C_1)@m_1 - .5*ln(det(C_1))\n",
    "        # decision criteria eq.7\n",
    "        estimators['gaussian bayesian classifier eq.44']['y_hat'].append(0) if g_0 > g_1 else estimators['gaussian bayesian classifier eq.44']['y_hat'].append(1)\n",
    "\n",
    "\n",
    "        ### ML with pool matrix -> eq.17\n",
    "        # pool matrix - eq.19\n",
    "        C = p_0*C_0 + p_1*C_1\n",
    "        # Q_k Mahalanobis distance of x from the class w_k (with pool matrix) \n",
    "        Q_0 = (x - m_0).T @ inv(C) @ (x - m_0)\n",
    "        Q_1 = (x - m_1).T @ inv(C) @ (x - m_1)\n",
    "        # decision criteria eq.18\n",
    "        estimators['ML with pool matrix eq.17']['y_hat'].append(0) if Q_0 < Q_1 else estimators['ML with pool matrix eq.17']['y_hat'].append(1)\n",
    "\n",
    "        ### ML with pool matrix -> eq.39\n",
    "        g_0 = m_0.T@inv(C)@x - .5*m_0.T@inv(C)@m_0\n",
    "        g_1 = m_1.T@inv(C)@x - .5*m_1.T@inv(C)@m_1\n",
    "        # decision criteria eq.7\n",
    "        estimators['ML with pool matrix eq.39']['y_hat'].append(0) if g_0 > g_1 else estimators['ML with pool matrix eq.39']['y_hat'].append(1)\n",
    "\n",
    "        # update the accuracy\n",
    "        for estimator in estimators.keys():\n",
    "            y_hat = estimators[estimator]['y_hat'][-1]\n",
    "            if y_hat  == y_n:\n",
    "               estimators[estimator]['accuracies'][-1] += 1/y_tst.size\n",
    "            # update confusion matrix\n",
    "            confusion_matrices[estimator][y_hat][y_n] += 1\n",
    "    # update the best and worst confusion matrix\n",
    "    for estimator in estimators.keys():\n",
    "        if estimators[estimator]['accuracies'][-1] > estimators[estimator]['best accuracy']:\n",
    "            estimators[estimator]['best accuracy'] = estimators[estimator]['accuracies'][-1]\n",
    "        elif estimators[estimator]['accuracies'][-1] < estimators[estimator]['worst accuracy']:\n",
    "            estimators[estimator]['worst accuracy'] = estimators[estimator]['accuracies'][-1]\n",
    "    if i+1 == N_iter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/tapyu/git/UFC_courses/reconhecimento_de_padrões/TC2/TC2.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tapyu/git/UFC_courses/reconhecimento_de_padr%C3%B5es/TC2/TC2.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m estimators\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tapyu/git/UFC_courses/reconhecimento_de_padr%C3%B5es/TC2/TC2.ipynb#ch0000013?line=1'>2</a>\u001b[0m     estimators[estimator][\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mean(estimators[estimator][\u001b[39m'\u001b[39;49m\u001b[39maccuracies\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tapyu/git/UFC_courses/reconhecimento_de_padr%C3%B5es/TC2/TC2.ipynb#ch0000013?line=2'>3</a>\u001b[0m     estimators[estimator][\u001b[39m'\u001b[39m\u001b[39mmedian\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m median(estimators[estimator][\u001b[39m'\u001b[39m\u001b[39maccuracies\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tapyu/git/UFC_courses/reconhecimento_de_padr%C3%B5es/TC2/TC2.ipynb#ch0000013?line=3'>4</a>\u001b[0m     estimators[estimator][\u001b[39m'\u001b[39m\u001b[39msd\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m stdev(estimators[estimator][\u001b[39m'\u001b[39m\u001b[39maccuracies\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracies'"
     ]
    }
   ],
   "source": [
    "for estimator in estimators.keys():\n",
    "    estimators[estimator]['mean'] = mean(estimators[estimator]['accuracies'])\n",
    "    estimators[estimator]['median'] = median(estimators[estimator]['accuracies'])\n",
    "    estimators[estimator]['sd'] = stdev(estimators[estimator]['accuracies'])\n",
    "    estimators[estimator]['min'] = min(estimators[estimator]['accuracies'])\n",
    "    estimators[estimator]['max'] = max(estimators[estimator]['accuracies'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0853d0cd0285211feef9c3c67460afc34f8dedda7de1cf38c0c86ad86676f201"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('reconhecimento-de-padrões-bKQRBPNU-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
